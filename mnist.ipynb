{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "\n",
    "def mnist_data():\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "    \n",
    "    Y_train = np_utils.to_categorical(y_train, 10)\n",
    "    Y_test = np_utils.to_categorical(y_test, 10)\n",
    "    \n",
    "    X_train = X_train.reshape([-1, 28, 28, 1])\n",
    "    X_test  = X_test.reshape([-1, 28, 28, 1])\n",
    "    return (X_train, Y_train), (X_test, Y_test)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADBCAYAAABIbSwnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124c1f3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# plot first six training images\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "for i in range(6):\n",
    "    ax = fig.add_subplot(1, 6, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(X_train[i], cmap='gray')\n",
    "    ax.set_title(str(y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "def network():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Flatten(input_shape=(28, 28, 1, )))\n",
    "    model.add(Dense(256))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network():\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "    input_shape = (28, 28, 1)\n",
    "    num_classes = 10\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # summarize the model\n",
    "    #model.summary()\n",
    "    #keras.utils.plot_model(model, to_file='model.png')\n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer #1 (named \"batch_normalization_3\" in the current model) was found to correspond to layer conv2d_17 in the save file. However the new layer batch_normalization_3 expects 4 weights, but the saved weights have 2 elements.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-60bb4d67b903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jordanburgess/.virtualenvs/dl/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m    736\u001b[0m                                                               reshape=reshape)\n\u001b[1;32m    737\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m                 \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jordanburgess/.virtualenvs/dl/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m   3185\u001b[0m                              \u001b[0;34m' weights, but the saved weights have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3186\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3187\u001b[0;31m                              ' elements.')\n\u001b[0m\u001b[1;32m   3188\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3189\u001b[0m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer #1 (named \"batch_normalization_3\" in the current model) was found to correspond to layer conv2d_17 in the save file. However the new layer batch_normalization_3 expects 4 weights, but the saved weights have 2 elements."
     ]
    }
   ],
   "source": [
    "model.load_weights('model_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected flatten_7_input to have 4 dimensions, but got array with shape (60000, 28, 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-c1a6e9d82b72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jordanburgess/.virtualenvs/dl/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/jordanburgess/.virtualenvs/dl/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1635\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1637\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1638\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jordanburgess/.virtualenvs/dl/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1481\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1483\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1484\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1485\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jordanburgess/.virtualenvs/dl/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected flatten_7_input to have 4 dimensions, but got array with shape (60000, 28, 28)"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=512, epochs=6, verbose=1, validation_data=(X_test, y_test))\n",
    "model.save_weights('model_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected flatten_7_input to have 4 dimensions, but got array with shape (10000, 28, 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-3c46044cfd5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jordanburgess/.virtualenvs/dl/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                                    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m                                    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                    steps=steps)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jordanburgess/.virtualenvs/dl/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1776\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `_test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jordanburgess/.virtualenvs/dl/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1481\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1483\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1484\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1485\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jordanburgess/.virtualenvs/dl/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected flatten_7_input to have 4 dimensions, but got array with shape (10000, 28, 28)"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : flatten_7_input, <keras.engine.topology.InputLayer object at 0x124abf860>\n",
      "1 : flatten_7, <keras.layers.core.Flatten object at 0x124abf908>\n",
      "2 : dense_14, <keras.layers.core.Dense object at 0x124ac9ef0>\n",
      "3 : batch_normalization_3, <keras.layers.normalization.BatchNormalization object at 0x124ac9550>\n",
      "4 : activation_9, <keras.layers.core.Activation object at 0x124ac9588>\n",
      "5 : dense_15, <keras.layers.core.Dense object at 0x124ac95c0>\n",
      "6 : batch_normalization_4, <keras.layers.normalization.BatchNormalization object at 0x124b17da0>\n",
      "7 : activation_10, <keras.layers.core.Activation object at 0x124b4b240>\n",
      "8 : dense_16, <keras.layers.core.Dense object at 0x124b3f630>\n",
      "9 : activation_11, <keras.layers.core.Activation object at 0x12743ab70>\n"
     ]
    }
   ],
   "source": [
    "import coremltools\n",
    "coreml_model = coremltools.converters.keras.convert(\n",
    "    model, input_names=\"image\", image_input_names='image',\n",
    "    class_labels=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input {\n",
      "  name: \"image\"\n",
      "  shortDescription: \"28x28 grayscaled pixel values between 0-1\"\n",
      "  type {\n",
      "    imageType {\n",
      "      width: 28\n",
      "      height: 28\n",
      "      colorSpace: GRAYSCALE\n",
      "    }\n",
      "  }\n",
      "}\n",
      "output {\n",
      "  name: \"output1\"\n",
      "  type {\n",
      "    dictionaryType {\n",
      "      stringKeyType {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "output {\n",
      "  name: \"classLabel\"\n",
      "  type {\n",
      "    stringType {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "predictedFeatureName: \"classLabel\"\n",
      "predictedProbabilitiesName: \"output1\"\n",
      "metadata {\n",
      "  shortDescription: \"MNIST handwriting recognition with a 3 layer network\"\n",
      "  author: \"jordan\"\n",
      "  license: \"MIT\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coreml_model.author = 'jordan'\n",
    "coreml_model.license = 'MIT'\n",
    "coreml_model.short_description = 'MNIST handwriting recognition with a 3 layer network'\n",
    "coreml_model.input_description['image'] = '28x28 grayscaled pixel values between 0-1'\n",
    "coreml_model.save('SimpleMnist.mlmodel')\n",
    "\n",
    "print(coreml_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output1': {'0': 0.0, '1': 0.0, '2': 0.0, '3': 1.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': 0.0}, 'classLabel': '3'}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAYL329OsCgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13155ac88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image  \n",
    "import numpy as np\n",
    "model =  coremltools.models.MLModel('SimpleMnist.mlmodel')\n",
    "im = Image.fromarray((np.reshape(mnist_data()[0][0][12]*255, (28, 28))).astype(np.uint8),\"L\")\n",
    "#im = Image.fromarray(mnist_data()[0][0][1].reshape(28,28).astype(np.float32), 'L')\n",
    "plt.imshow(im)\n",
    "predictions = model.predict({'image': im})\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output1': {'0': 0.0, '1': 0.0, '2': 0.0, '3': 0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 1.0, '9': 0.0}, 'classLabel': '8'}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124b3f4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#im = Image.open(\"IMG_0181.JPG\") #5\n",
    "#im = Image.open(\"IMG_5349.JPG\") #1\n",
    "#im = Image.open(\"IMG_9925.JPG\") #4\n",
    "im = Image.open(\"IMG_4057.JPG\") #0\n",
    "im = Image.open(\"IMG_9315.JPG\") #0\n",
    "\n",
    "from PIL import ImageEnhance\n",
    "#im = ImageEnhance.Contrast(im).enhance(2.0)\n",
    "from PIL import ImageFilter\n",
    "\n",
    "size = 28, 28\n",
    "#im.thumbnail(size)\n",
    "im = im.rotate(-90)\n",
    "im = im.resize(size)\n",
    "im = im.convert(\"L\")\n",
    "#im = im.filter(ImageFilter.MaxFilter(3))\n",
    "#im.crop((0,0,28,28))\n",
    "plt.imshow(im)\n",
    "predictions = model.predict({'image': im})\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
